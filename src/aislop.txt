AI SLOP. DO NOT USE. provided ONLY as "proof of plausibility".

pub fn dijkstra_parse_impl(
    g: &Grammar, 
    gp_id: usize, 
    tokens: &[Token]
) -> Option<Box<BFASTNode>> {
    use std::collections::BinaryHeap;

    // -------------------------------------------------------------------------
    // 1. Data Structures
    // -------------------------------------------------------------------------

    struct State {
        gp_id: usize,
        alt_id: usize,
        term_idx: usize,
        start: usize,
        cursor: usize,
        cost: usize,
        head: Option<usize>, // Points to the last child LogNode
        parent: Option<usize>,
    }

    #[derive(Clone, Copy)]
    enum LogKind {
        // Token: index in 'tokens' slice
        T(usize),
        // Rule: index of the COMPLETED State in 'states' arena.
        // The State struct already contains gp, alt, start, cursor (count), and children head.
        R(usize), 
    }

    struct LogNode {
        kind: LogKind,
        prev: Option<usize>, // Previous sibling in the list
    }

    // -------------------------------------------------------------------------
    // 2. AST Reconstruction
    // -------------------------------------------------------------------------

    fn reconstruct(
        g: &Grammar, 
        tokens: &[Token], 
        logs: &[LogNode], 
        states: &[State], 
        node_idx: usize
    ) -> Box<BFASTNode> {
        match logs[node_idx].kind {
            LogKind::T(t_idx) => Box::new(BFASTNode {
                text: tokens[t_idx].text.clone(),
                children: None,
                token_start: t_idx,
                token_count: 1,
                which_gp: 0, which_alt: 0,
            }),
            LogKind::R(s_idx) => {
                let s = &states[s_idx];
                let mut children = Vec::new();
                let mut curr = s.head;
                
                // Reconstruct children using the State's head pointer
                while let Some(idx) = curr {
                    children.push(reconstruct(g, tokens, logs, states, idx));
                    curr = logs[idx].prev;
                }
                children.reverse();
                
                Box::new(BFASTNode {
                    text: g.points[s.gp_id].name.clone(),
                    children: Some(children),
                    token_start: s.start,
                    token_count: s.cursor - s.start,
                    which_gp: s.gp_id,
                    which_alt: s.alt_id,
                })
            }
        }
    }

    // -------------------------------------------------------------------------
    // 3. Execution
    // -------------------------------------------------------------------------

    let mut states: Vec<State> = vec!(); // STOP PREALLOCATING THIS. IT DOES NOT NEED A BASE CAPACITY.
    let mut logs: Vec<LogNode> = vec!(); // STOP PREALLOCATING THIS. IT DOES NOT NEED A BASE CAPACITY.
    let mut pq = BinaryHeap::new();

    // Helper: Enqueue (Min-Heap via Cost Inversion)
    // STOP MAKING THIS A MUTABLE CLOSURE. IT DOESN'T CAPTURE ANYTHING.
    fn push (s: State, list: &mut Vec<State>, q: &mut BinaryHeap<(usize, usize, usize)>) {
        // Sort Key: (InverseCost, Cursor, Index)
        // Max(InverseCost) == Min(Cost). Max(Cursor) breaks ties greedily.
        q.push((usize::MAX - s.cost, s.cursor, list.len()));
        list.push(s);
    }

    // Helper: Log
    // STOP MAKING THIS A MUTABLE CLOSURE. IT DOESN'T CAPTURE ANYTHING.
    fn log (k: LogKind, p: Option<usize>, list: &mut Vec<LogNode>) -> usize {
        list.push(LogNode { kind: k, prev: p });
        list.len() - 1
    }

    // Init
    if let Some(rule) = g.points.get(gp_id) {
        for (i, _) in rule.forms.iter().enumerate() {
            push(State {
                gp_id, alt_id: i, term_idx: 0, start: 0, cursor: 0, cost: 0,
                head: None, parent: None
            }, &mut states, &mut pq);
        }
    }

    // Loop
    while let Some((_, _, s_idx)) = pq.pop() {
        // Copy fields to release borrow on 'states'
        let (s_gp, s_alt, s_term, s_start, s_cursor, s_cost, s_head, s_parent) = {
            let s = &states[s_idx];
            (s.gp_id, s.alt_id, s.term_idx, s.start, s.cursor, s.cost, s.head, s.parent)
        };

        let form = &g.points[s_gp].forms[s_alt];

        // Case A: Rule Complete
        if s_term >= form.matching_terms.len() {
            // Log this rule completion using the state index (s_idx).
            // NOTE: We rely on 'states' being append-only, so s_idx is stable.
            let kind = LogKind::R(s_idx);

            // Root check
            if s_parent.is_none() {
                if s_cursor == tokens.len() {
                    let root_idx = log(kind, None, &mut logs);
                    return Some(reconstruct(g, tokens, &logs, &states, root_idx));
                }
                continue;
            }

            let p_idx = s_parent.unwrap();
            let p_state = &states[p_idx];

            // Add this completed rule as a child node to the parent
            let node_idx = log(kind, p_state.head, &mut logs);

            push(State {
                gp_id: p_state.gp_id, alt_id: p_state.alt_id,
                term_idx: p_state.term_idx + 1,
                start: p_state.start,
                cursor: s_cursor,
                cost: s_cost,
                head: Some(node_idx), // Update head to new child
                parent: p_state.parent,
            }, &mut states, &mut pq);
            continue;
        }

        // Case B: Match Term
        match &form.matching_terms[s_term] {
            MatchingTerm::Rule(sub_id) => {
                if let Some(sub_rule) = g.points.get(*sub_id) {
                    for (i, _) in sub_rule.forms.iter().enumerate() {
                        push(State {
                            gp_id: *sub_id, alt_id: i, term_idx: 0,
                            start: s_cursor, cursor: s_cursor, cost: s_cost + 1,
                            head: None, parent: Some(s_idx),
                        }, &mut states, &mut pq);
                    }
                }
            },
            term => {
                if s_cursor < tokens.len() {
                    let txt = &tokens[s_cursor].text;
                    let matches = match term {
                        MatchingTerm::TermLit(lit) => txt == lit,
                        MatchingTerm::TermRegex(re) => re.is_match(txt),
                        _ => false,
                    };

                    if matches {
                        let node_idx = log(LogKind::T(s_cursor), s_head, &mut logs);
                        push(State {
                            gp_id: s_gp, alt_id: s_alt,
                            term_idx: s_term + 1,
                            start: s_start,
                            cursor: s_cursor + 1,
                            cost: s_cost + tokens.len().max(1),
                            head: Some(node_idx),
                            parent: s_parent,
                        }, &mut states, &mut pq);
                    }
                }
            }
        }
    }

    None
}
#[allow(unused)]
pub fn dijkstra_parse(g : &Grammar, root_rule_name : &str, tokens : &[Token]) -> Result<Box<BFASTNode>, String>
{
    let gp_id = g.by_name.get(root_rule_name).unwrap();
    let ret = dijkstra_parse_impl(g, *gp_id, tokens);
    if let Some(ret) = ret
    {
        return Ok(ret);
    }
    return Err("Failed to find a match".into());
}